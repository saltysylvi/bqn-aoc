# A super jank json tokenizer/parser in <20 loc hehe <3
Tokenize â† {
    ns â† >âŸœÂ» n â† (ğ•©='-')âˆ¨ğ•©âˆŠ'0'+â†•10
    numbers â† {'-'=âŠ‘ğ•©? -ğ•Š1â†“ğ•©; 10âŠ¸Ã—âŠ¸+ËœÂ´âŒ½ğ•©-'0'}Â¨ (1-ËœnÃ—+`ns)âŠ”ğ•©
    s â† â‰ `q â† '"'=ğ•©
    strings â† (1-Ëœ(q<s)Ã—+`sâˆ§q)âŠ”ğ•©
    t â† ns âˆ¨ (sâˆ§q) âˆ¨ ğ•©âˆŠ"[]{}"
    tokens â† 'a'Â¨âŒ¾((t/sâˆ§q)âŠ¸/) '0'Â¨âŒ¾((t/ns)âŠ¸/) t/ğ•©
    tokensâ€¿numbersâ€¿strings
}
Parse â† {ğ•Š tâ€¿nâ€¿s:
    { '0'â€¿t: âŸ¨âŸ¨'n',âŠ‘nâŸ©, t, 1â†“n, sâŸ©;
      'a'â€¿t: âŸ¨âŸ¨'s',âŠ‘sâŸ©, t, n, 1â†“sâŸ©;
      '['â€¿t: lâ†âŸ¨âŸ© â‹„ vâ†@ â‹„ {ğ•Š:vâ€¿tâ€¿nâ€¿sâ†©Parse tâ€¿nâ€¿s â‹„ lâˆ¾â†©<v}â€¢_while_{ğ•Š:']'â‰ âŠ‘t}@ â‹„ âŸ¨âŸ¨'l',lâŸ©,1â†“t,n,sâŸ©;
      '{'â€¿t: dâ†âŸ¨âŸ© â‹„ vâ†@ â‹„ {ğ•Š:vâ€¿tâ€¿nâ€¿sâ†©Parse tâ€¿nâ€¿s â‹„ dâˆ¾â†©<v}â€¢_while_{ğ•Š:'}'â‰ âŠ‘t}@ â‹„ âŸ¨âŸ¨'d',â‰âˆ˜â€¿2â¥ŠdâŸ©,1â†“t,n,sâŸ©
    } âŸ¨âŠ‘t, 1â†“tâŸ©
}
tâ€¿nâ€¿s â† Tokenize â€¢FChars "inputs/12.txt"
â€¢Show +Â´n
json â† âŠ‘Parse tâ€¿nâ€¿s
Sum â† {ğ•Š typeâ€¿val:
    { type='n'? val; # number
      type='s'? 0; # string
      type='l'? +Â´SumÂ¨val; # list
      (type='d')âˆ§Â¬âŠ‘'s'â€¿"red"<âŠ¸âˆŠ1âŠval ? +Â´SumÂ¨1âŠval; 0 # dict/obj
    }
}
â€¢Show Sum json
